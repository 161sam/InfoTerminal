{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "142d0f3d",
   "metadata": {},
   "source": [
    "# Exercise Â· Network to Timeline\n",
    "\n",
    "Complete the parsing and timeline steps so the synthetic packet capture yields flows, DNS, and HTTP artefacts plus a consolidated CSV/JSON timeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f84060",
   "metadata": {},
   "outputs": [],
   "source": [
    "DRY_RUN = True\n",
    "from notebooks._utils.common import *\n",
    "\n",
    "DRY_RUN.value = True\n",
    "CLI_OK.value = shell_available('forensic-cli')\n",
    "LAB_ID = '20_network_exercise'\n",
    "LAB_ROOT = lab_root(LAB_ID)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8072987c",
   "metadata": {},
   "source": [
    "## Provided synthetic capture\n",
    "\n",
    "The dataset mirrors the lab so focus on implementing the transformation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f55fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "pcap_records = [\n",
    "    {\n",
    "        'type': 'flow',\n",
    "        'timestamp': '2024-01-01T09:00:00Z',\n",
    "        'src_ip': '10.0.0.10',\n",
    "        'src_port': 49512,\n",
    "        'dst_ip': '198.51.100.20',\n",
    "        'dst_port': 443,\n",
    "        'protocol': 'tcp',\n",
    "        'bytes_sent': 512,\n",
    "        'bytes_received': 2048,\n",
    "        'duration_ms': 350,\n",
    "    },\n",
    "    {\n",
    "        'type': 'flow',\n",
    "        'timestamp': '2024-01-01T09:00:02Z',\n",
    "        'src_ip': '10.0.0.10',\n",
    "        'src_port': 49513,\n",
    "        'dst_ip': '203.0.113.53',\n",
    "        'dst_port': 53,\n",
    "        'protocol': 'udp',\n",
    "        'bytes_sent': 128,\n",
    "        'bytes_received': 128,\n",
    "        'duration_ms': 40,\n",
    "    },\n",
    "    {\n",
    "        'type': 'dns',\n",
    "        'timestamp': '2024-01-01T09:00:02Z',\n",
    "        'query': 'example.internal',\n",
    "        'response': '203.0.113.53',\n",
    "        'rcode': 'NOERROR',\n",
    "    },\n",
    "    {\n",
    "        'type': 'flow',\n",
    "        'timestamp': '2024-01-01T09:00:05Z',\n",
    "        'src_ip': '10.0.0.10',\n",
    "        'src_port': 49514,\n",
    "        'dst_ip': '93.184.216.34',\n",
    "        'dst_port': 80,\n",
    "        'protocol': 'tcp',\n",
    "        'bytes_sent': 1024,\n",
    "        'bytes_received': 8192,\n",
    "        'duration_ms': 1020,\n",
    "    },\n",
    "    {\n",
    "        'type': 'http',\n",
    "        'timestamp': '2024-01-01T09:00:05Z',\n",
    "        'method': 'GET',\n",
    "        'host': 'example.com',\n",
    "        'uri': '/index.html',\n",
    "        'status': 200,\n",
    "        'user_agent': 'LabClient/1.0',\n",
    "    },\n",
    "]\n",
    "\n",
    "pcap_path = LAB_ROOT / 'inputs' / 'pcap.json'\n",
    "json_dump_sorted(pcap_records, pcap_path)\n",
    "pcap_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19edac3",
   "metadata": {},
   "source": [
    "## TODO: emit deterministic network artefacts\n",
    "\n",
    "Populate `flows`, `dns_records`, and `http_records` based on the `pcap_records` input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ea5477",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "network_dir = LAB_ROOT / 'outputs' / 'network'\n",
    "network_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# TODO: build sorted flow, DNS, and HTTP collections from pcap_records.\n",
    "flows: list[dict]\n",
    "dns_records: list[dict]\n",
    "http_records: list[dict]\n",
    "\n",
    "raise NotImplementedError('Implement network artefact extraction.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e6144a",
   "metadata": {},
   "source": [
    "## TODO: timeline aggregation\n",
    "\n",
    "Use the artefacts to craft a combined timeline and persist it as JSON and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a21482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: create timeline_events, timeline_json_path, and timeline_csv_path.\n",
    "raise NotImplementedError('Assemble the consolidated timeline outputs.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
